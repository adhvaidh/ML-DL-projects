{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\Adhvaidh\\\\Desktop\\\\DL deployment\")\n",
    "ds = pd.read_csv(\"GBP_INR train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Change %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>May 15, 2002</td>\n",
       "      <td>71.575</td>\n",
       "      <td>70.929</td>\n",
       "      <td>71.575</td>\n",
       "      <td>70.802</td>\n",
       "      <td>0.78%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May 16, 2002</td>\n",
       "      <td>71.356</td>\n",
       "      <td>71.462</td>\n",
       "      <td>71.764</td>\n",
       "      <td>71.159</td>\n",
       "      <td>-0.31%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>May 17, 2002</td>\n",
       "      <td>71.405</td>\n",
       "      <td>71.252</td>\n",
       "      <td>71.666</td>\n",
       "      <td>71.198</td>\n",
       "      <td>0.07%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>May 20, 2002</td>\n",
       "      <td>71.478</td>\n",
       "      <td>71.510</td>\n",
       "      <td>71.811</td>\n",
       "      <td>71.320</td>\n",
       "      <td>0.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May 21, 2002</td>\n",
       "      <td>71.475</td>\n",
       "      <td>71.398</td>\n",
       "      <td>71.607</td>\n",
       "      <td>71.061</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   Price    Open    High     Low Change %\n",
       "0  May 15, 2002  71.575  70.929  71.575  70.802    0.78%\n",
       "1  May 16, 2002  71.356  71.462  71.764  71.159   -0.31%\n",
       "2  May 17, 2002  71.405  71.252  71.666  71.198    0.07%\n",
       "3  May 20, 2002  71.478  71.510  71.811  71.320    0.10%\n",
       "4  May 21, 2002  71.475  71.398  71.607  71.061    0.00%"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 71.575],\n",
       "       [ 71.356],\n",
       "       [ 71.405],\n",
       "       ...,\n",
       "       [102.115],\n",
       "       [102.41 ],\n",
       "       [102.421]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds.iloc[:, 1:2].values\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "ds_sc = sc.fit_transform(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, len(ds_sc)):\n",
    "    X_train.append(ds_sc[i-60:i, 0])\n",
    "    y_train.append(ds_sc[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4906, 60)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "#as input format for RNN is (batchsize, timeSteps, input dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 60, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 60, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 60, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "regressor.add(LSTM(units = 60, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "regressor.add(LSTM(units = 60, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "#Output layer\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 60, 60)            14880     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 60)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 60)            29040     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 60)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 60, 60)            29040     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60, 60)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 60, 60)            29040     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60, 60)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 60, 60)            29040     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 60, 60)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 60, 1)             61        \n",
      "=================================================================\n",
      "Total params: 131,101\n",
      "Trainable params: 131,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "164/164 [==============================] - 22s 83ms/step - loss: 0.0574\n",
      "Epoch 2/150\n",
      "164/164 [==============================] - 16s 97ms/step - loss: 0.0132\n",
      "Epoch 3/150\n",
      "164/164 [==============================] - 16s 98ms/step - loss: 0.0098\n",
      "Epoch 4/150\n",
      "164/164 [==============================] - 21s 128ms/step - loss: 0.0085\n",
      "Epoch 5/150\n",
      "164/164 [==============================] - 19s 117ms/step - loss: 0.0073\n",
      "Epoch 6/150\n",
      "164/164 [==============================] - 20s 120ms/step - loss: 0.0069\n",
      "Epoch 7/150\n",
      "164/164 [==============================] - 20s 121ms/step - loss: 0.0067\n",
      "Epoch 8/150\n",
      "164/164 [==============================] - 21s 125ms/step - loss: 0.0062\n",
      "Epoch 9/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0059\n",
      "Epoch 10/150\n",
      "164/164 [==============================] - 21s 125ms/step - loss: 0.0059\n",
      "Epoch 11/150\n",
      "164/164 [==============================] - 21s 127ms/step - loss: 0.0060\n",
      "Epoch 12/150\n",
      "164/164 [==============================] - 21s 129ms/step - loss: 0.0056\n",
      "Epoch 13/150\n",
      "164/164 [==============================] - 21s 130ms/step - loss: 0.0057\n",
      "Epoch 14/150\n",
      "164/164 [==============================] - 22s 131ms/step - loss: 0.0058\n",
      "Epoch 15/150\n",
      "164/164 [==============================] - 21s 131ms/step - loss: 0.0056\n",
      "Epoch 16/150\n",
      "164/164 [==============================] - 23s 139ms/step - loss: 0.0056\n",
      "Epoch 17/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0054\n",
      "Epoch 18/150\n",
      "164/164 [==============================] - 22s 133ms/step - loss: 0.0054\n",
      "Epoch 19/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0054\n",
      "Epoch 20/150\n",
      "164/164 [==============================] - 22s 137ms/step - loss: 0.0053\n",
      "Epoch 21/150\n",
      "164/164 [==============================] - 23s 140ms/step - loss: 0.0052\n",
      "Epoch 22/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0053\n",
      "Epoch 23/150\n",
      "164/164 [==============================] - 23s 139ms/step - loss: 0.0052\n",
      "Epoch 24/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0052\n",
      "Epoch 25/150\n",
      "164/164 [==============================] - 23s 139ms/step - loss: 0.0054\n",
      "Epoch 26/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0054\n",
      "Epoch 27/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0052\n",
      "Epoch 28/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0053\n",
      "Epoch 29/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0051\n",
      "Epoch 30/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0051\n",
      "Epoch 31/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0051\n",
      "Epoch 32/150\n",
      "164/164 [==============================] - 22s 137ms/step - loss: 0.0053\n",
      "Epoch 33/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0051\n",
      "Epoch 34/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0052\n",
      "Epoch 35/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0049\n",
      "Epoch 36/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0050\n",
      "Epoch 37/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0052\n",
      "Epoch 38/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0052\n",
      "Epoch 39/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0050\n",
      "Epoch 40/150\n",
      "164/164 [==============================] - 22s 137ms/step - loss: 0.0050\n",
      "Epoch 41/150\n",
      "164/164 [==============================] - 23s 141ms/step - loss: 0.0049\n",
      "Epoch 42/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0050\n",
      "Epoch 43/150\n",
      "164/164 [==============================] - 24s 145ms/step - loss: 0.0052\n",
      "Epoch 44/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0051\n",
      "Epoch 45/150\n",
      "164/164 [==============================] - 23s 142ms/step - loss: 0.0049\n",
      "Epoch 46/150\n",
      "164/164 [==============================] - 23s 138ms/step - loss: 0.0051\n",
      "Epoch 47/150\n",
      "164/164 [==============================] - 23s 140ms/step - loss: 0.0050\n",
      "Epoch 48/150\n",
      "164/164 [==============================] - 22s 137ms/step - loss: 0.0049\n",
      "Epoch 49/150\n",
      "164/164 [==============================] - 23s 139ms/step - loss: 0.0050\n",
      "Epoch 50/150\n",
      "164/164 [==============================] - 23s 138ms/step - loss: 0.0051\n",
      "Epoch 51/150\n",
      "164/164 [==============================] - 22s 137ms/step - loss: 0.0049\n",
      "Epoch 52/150\n",
      "164/164 [==============================] - 23s 138ms/step - loss: 0.0049\n",
      "Epoch 53/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0050\n",
      "Epoch 54/150\n",
      "164/164 [==============================] - 22s 132ms/step - loss: 0.0050\n",
      "Epoch 55/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0050\n",
      "Epoch 56/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0050\n",
      "Epoch 57/150\n",
      "164/164 [==============================] - 23s 139ms/step - loss: 0.0050\n",
      "Epoch 58/150\n",
      "164/164 [==============================] - 22s 137ms/step - loss: 0.0048\n",
      "Epoch 59/150\n",
      "164/164 [==============================] - 22s 137ms/step - loss: 0.0049\n",
      "Epoch 60/150\n",
      "164/164 [==============================] - 22s 133ms/step - loss: 0.0048\n",
      "Epoch 61/150\n",
      "164/164 [==============================] - 23s 140ms/step - loss: 0.0050\n",
      "Epoch 62/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0048\n",
      "Epoch 63/150\n",
      "164/164 [==============================] - 23s 139ms/step - loss: 0.0049\n",
      "Epoch 64/150\n",
      "164/164 [==============================] - 22s 137ms/step - loss: 0.0050\n",
      "Epoch 65/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0048\n",
      "Epoch 66/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0049\n",
      "Epoch 67/150\n",
      "164/164 [==============================] - 22s 133ms/step - loss: 0.0048\n",
      "Epoch 68/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0048\n",
      "Epoch 69/150\n",
      "164/164 [==============================] - 23s 137ms/step - loss: 0.0049\n",
      "Epoch 70/150\n",
      "164/164 [==============================] - 22s 137ms/step - loss: 0.0046\n",
      "Epoch 71/150\n",
      "164/164 [==============================] - 23s 138ms/step - loss: 0.0049\n",
      "Epoch 72/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0049\n",
      "Epoch 73/150\n",
      "164/164 [==============================] - 23s 139ms/step - loss: 0.0047\n",
      "Epoch 74/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0047\n",
      "Epoch 75/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0047\n",
      "Epoch 76/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0048\n",
      "Epoch 77/150\n",
      "164/164 [==============================] - 22s 133ms/step - loss: 0.0050\n",
      "Epoch 78/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0048\n",
      "Epoch 79/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0046\n",
      "Epoch 80/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0048\n",
      "Epoch 81/150\n",
      "164/164 [==============================] - 23s 139ms/step - loss: 0.0047\n",
      "Epoch 82/150\n",
      "164/164 [==============================] - 22s 133ms/step - loss: 0.0046\n",
      "Epoch 83/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0048\n",
      "Epoch 84/150\n",
      "164/164 [==============================] - 23s 139ms/step - loss: 0.0049\n",
      "Epoch 85/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0047\n",
      "Epoch 86/150\n",
      "164/164 [==============================] - 22s 133ms/step - loss: 0.0049\n",
      "Epoch 87/150\n",
      "164/164 [==============================] - 22s 133ms/step - loss: 0.0047\n",
      "Epoch 88/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0047\n",
      "Epoch 89/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0047\n",
      "Epoch 90/150\n",
      "164/164 [==============================] - 22s 132ms/step - loss: 0.0046\n",
      "Epoch 91/150\n",
      "164/164 [==============================] - 22s 133ms/step - loss: 0.0046\n",
      "Epoch 92/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0047\n",
      "Epoch 93/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0045\n",
      "Epoch 94/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0048\n",
      "Epoch 95/150\n",
      "164/164 [==============================] - 22s 132ms/step - loss: 0.0047\n",
      "Epoch 96/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 22s 132ms/step - loss: 0.0049\n",
      "Epoch 97/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0044\n",
      "Epoch 98/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0046\n",
      "Epoch 99/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0045\n",
      "Epoch 100/150\n",
      "164/164 [==============================] - 22s 133ms/step - loss: 0.0045\n",
      "Epoch 101/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0043\n",
      "Epoch 102/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0044\n",
      "Epoch 103/150\n",
      "164/164 [==============================] - 22s 133ms/step - loss: 0.0045\n",
      "Epoch 104/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0044\n",
      "Epoch 105/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0045\n",
      "Epoch 106/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0044\n",
      "Epoch 107/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0043\n",
      "Epoch 108/150\n",
      "164/164 [==============================] - 22s 133ms/step - loss: 0.0043\n",
      "Epoch 109/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0044\n",
      "Epoch 110/150\n",
      "164/164 [==============================] - 23s 138ms/step - loss: 0.0043\n",
      "Epoch 111/150\n",
      "164/164 [==============================] - 23s 138ms/step - loss: 0.0044\n",
      "Epoch 112/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0043\n",
      "Epoch 113/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0042\n",
      "Epoch 114/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0041\n",
      "Epoch 115/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0043\n",
      "Epoch 116/150\n",
      "164/164 [==============================] - 22s 132ms/step - loss: 0.0042\n",
      "Epoch 117/150\n",
      "164/164 [==============================] - 22s 133ms/step - loss: 0.0042\n",
      "Epoch 118/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0041\n",
      "Epoch 119/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0040\n",
      "Epoch 120/150\n",
      "164/164 [==============================] - 23s 138ms/step - loss: 0.0043\n",
      "Epoch 121/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0042\n",
      "Epoch 122/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0041\n",
      "Epoch 123/150\n",
      "164/164 [==============================] - 22s 133ms/step - loss: 0.0042\n",
      "Epoch 124/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0041\n",
      "Epoch 125/150\n",
      "164/164 [==============================] - 22s 137ms/step - loss: 0.0040\n",
      "Epoch 126/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0040\n",
      "Epoch 127/150\n",
      "164/164 [==============================] - 23s 137ms/step - loss: 0.0043\n",
      "Epoch 128/150\n",
      "164/164 [==============================] - 23s 138ms/step - loss: 0.0042\n",
      "Epoch 129/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0040\n",
      "Epoch 130/150\n",
      "164/164 [==============================] - 23s 139ms/step - loss: 0.0041\n",
      "Epoch 131/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0040\n",
      "Epoch 132/150\n",
      "164/164 [==============================] - 22s 131ms/step - loss: 0.0040\n",
      "Epoch 133/150\n",
      "164/164 [==============================] - 22s 133ms/step - loss: 0.0041\n",
      "Epoch 134/150\n",
      "164/164 [==============================] - 23s 143ms/step - loss: 0.0038\n",
      "Epoch 135/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0040\n",
      "Epoch 136/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0039\n",
      "Epoch 137/150\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 0.0040\n",
      "Epoch 138/150\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 0.0038\n",
      "Epoch 139/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0040\n",
      "Epoch 140/150\n",
      "164/164 [==============================] - 21s 128ms/step - loss: 0.0038\n",
      "Epoch 141/150\n",
      "164/164 [==============================] - 21s 129ms/step - loss: 0.0038\n",
      "Epoch 142/150\n",
      "164/164 [==============================] - 21s 128ms/step - loss: 0.0037\n",
      "Epoch 143/150\n",
      "164/164 [==============================] - 21s 129ms/step - loss: 0.0037\n",
      "Epoch 144/150\n",
      "164/164 [==============================] - 21s 129ms/step - loss: 0.0038\n",
      "Epoch 145/150\n",
      "164/164 [==============================] - 21s 129ms/step - loss: 0.0037\n",
      "Epoch 146/150\n",
      "164/164 [==============================] - 21s 127ms/step - loss: 0.0038\n",
      "Epoch 147/150\n",
      "164/164 [==============================] - 21s 129ms/step - loss: 0.0038\n",
      "Epoch 148/150\n",
      "164/164 [==============================] - 22s 134ms/step - loss: 0.0037\n",
      "Epoch 149/150\n",
      "164/164 [==============================] - 26s 159ms/step - loss: 0.0037\n",
      "Epoch 150/150\n",
      "164/164 [==============================] - 25s 154ms/step - loss: 0.0037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x212f26805e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 150, batch_size = 30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv('GBP INR test.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = pd.read_csv(\"GBP_INR train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-2925d0511042>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mpredicted_stock_price\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mpredicted_stock_price\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_stock_price\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m         X = check_array(X, copy=self.copy, dtype=FLOAT_DTYPES,\n\u001b[0m\u001b[0;32m    430\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0m\u001b[0;32m    641\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "dataset_total = pd.concat((ds_train['Price'], dataset_test['Price']), axis = 0)\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs = sc.transform(inputs)\n",
    "X_test = []\n",
    "for i in range(60, 80):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.8086604 ],\n",
       "        [0.82725155],\n",
       "        [0.82591975],\n",
       "        ...,\n",
       "        [0.88890946],\n",
       "        [0.8922514 ],\n",
       "        [0.89397204]],\n",
       "\n",
       "       [[0.8112734 ],\n",
       "        [0.823781  ],\n",
       "        [0.8328934 ],\n",
       "        ...,\n",
       "        [0.8913082 ],\n",
       "        [0.8929064 ],\n",
       "        [0.89743745]],\n",
       "\n",
       "       [[0.8097033 ],\n",
       "        [0.83364165],\n",
       "        [0.8313945 ],\n",
       "        ...,\n",
       "        [0.89281285],\n",
       "        [0.897408  ],\n",
       "        [0.90056   ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.8177296 ],\n",
       "        [0.83668417],\n",
       "        [0.8395393 ],\n",
       "        ...,\n",
       "        [0.8907194 ],\n",
       "        [0.89225334],\n",
       "        [0.8886366 ]],\n",
       "\n",
       "       [[0.816233  ],\n",
       "        [0.83702224],\n",
       "        [0.8423072 ],\n",
       "        ...,\n",
       "        [0.89140224],\n",
       "        [0.88788605],\n",
       "        [0.88911176]],\n",
       "\n",
       "       [[0.81643546],\n",
       "        [0.8423874 ],\n",
       "        [0.8455726 ],\n",
       "        ...,\n",
       "        [0.88696903],\n",
       "        [0.888036  ],\n",
       "        [0.8834853 ]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_stock_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-8676d6fffff8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_stock_price\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m         X = check_array(X, copy=self.copy, dtype=FLOAT_DTYPES,\n\u001b[0m\u001b[0;32m    430\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0m\u001b[0;32m    641\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[102.48564 ],\n",
       "       [102.8134  ],\n",
       "       [103.07985 ],\n",
       "       [103.1015  ],\n",
       "       [102.955376],\n",
       "       [102.99273 ],\n",
       "       [103.70819 ],\n",
       "       [103.82532 ],\n",
       "       [103.81153 ],\n",
       "       [103.44731 ],\n",
       "       [103.48453 ],\n",
       "       [103.420746],\n",
       "       [103.28808 ],\n",
       "       [103.27657 ],\n",
       "       [103.10355 ],\n",
       "       [102.70437 ],\n",
       "       [102.77542 ],\n",
       "       [102.65299 ],\n",
       "       [102.693954],\n",
       "       [102.52104 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_stock_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(real_stock_price, color = 'red', label = 'Real GBP INR Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted GBP INR Price')\n",
    "plt.title('GBP INR Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('GBP INR Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "regressor.save('gbp_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
